settings,validation,test,training time,inference time
Optimized,0.7390000224113464,0.7239999771118164,180.3894579410553,0.38814854621887207
Default,0.7440000176429749,0.7365000247955322,75.04433822631836,0.41283535957336426
Optimized,0.7638000249862671,0.7483999729156494,245.61086511611938,0.4083833694458008
Default,0.7422000169754028,0.7177000045776367,194.5301160812378,0.40591859817504883
Optimized,0.7630000114440918,0.7371000051498413,779.574889421463,0.3921175003051758
Default,0.7462000250816345,0.7301999926567078,84.20602464675903,0.49971890449523926
Optimized,0.7820000052452087,0.7696999907493591,256.1914885044098,0.46317577362060547
Default,0.7483999729156494,0.732699990272522,122.36153292655945,0.7258644104003906
Optimized,0.771399974822998,0.7613999843597412,338.73087430000305,0.47266626358032227
Default,0.7239999771118164,0.7088000178337097,68.18266463279724,0.49771571159362793
Dropout,0.7229999899864197,0.7117000222206116,143.7930202484131,0.5107557773590088
Dropout,0.7121999859809875,0.6904000043869019,141.40791773796082,0.4735753536224365
Dropout,0.7085999846458435,0.699999988079071,82.6636483669281,0.5171582698822021
Dropout,0.741599977016449,0.7233999967575073,104.52407431602478,0.503190279006958
Dropout,0.7075999975204468,0.6973000168800354,60.864400148391724,0.5231947898864746
Gradient Dropout,0.7203999757766724,0.7149999737739563,130.52809357643127,0.4974837303161621
Gradient Dropout,0.7753999829292297,0.7646999955177307,257.1510455608368,0.4806325435638428
Gradient Dropout,0.7735999822616577,0.7544000148773193,558.5668199062347,0.4636671543121338
Gradient Dropout,0.7789999842643738,0.7588000297546387,193.17535734176636,0.5200948715209961
Gradient Dropout,0.7806000113487244,0.7799999713897705,412.8122069835663,0.4752073287963867
Activation,0.795199990272522,0.7757999897003174,265.8757834434509,0.5033979415893555
Activation,0.7918000221252441,0.7806000113487244,240.44363713264465,0.4845919609069824
Activation,0.7904000282287598,0.7750999927520752,263.284334897995,0.46181774139404297
Activation,0.7918000221252441,0.7724000215530396,301.17041873931885,0.46781396865844727
Activation,0.795799970626831,0.7763000130653381,413.62473726272583,0.4921712875366211
Input,0.7814000248908997,0.771399974822998,320.8862588405609,0.5011537075042725
Input,0.7843999862670898,0.7682999968528748,535.271018743515,0.4502885341644287
Input,0.7644000053405762,0.7462999820709229,351.1177818775177,0.44759058952331543
Input,0.7817999720573425,0.7584999799728394,279.74652338027954,0.5246124267578125
Input,0.7802000045776367,0.76910001039505,347.2085211277008,0.49683594703674316
Loss,0.7807999849319458,0.7720000147819519,316.26118564605713,0.49877500534057617
Loss,0.775600016117096,0.7717999815940857,351.63289499282837,0.460465669631958
Loss,0.0957999974489212,0.10000000149011612,46.72913646697998,0.4946305751800537
Loss,0.7904000282287598,0.7699999809265137,585.1965894699097,0.45091915130615234
Loss,0.7767999768257141,0.7646999955177307,236.92870807647705,0.5063173770904541
Batch,0.7720000147819519,0.761900007724762,384.7703104019165,0.48158717155456543
Batch,0.09759999811649323,0.10000000149011612,191.485675573349,0.5138125419616699
Batch,0.7350000143051147,0.713100016117096,188.77070546150208,0.5377483367919922
Batch,0.7544000148773193,0.7452999949455261,823.8873815536499,0.4674186706542969
Batch,0.7508000135421753,0.73580002784729,556.5584907531738,0.5013246536254883
Dropout+Batch,0.7950000166893005,0.7789999842643738,228.07687664031982,0.5319766998291016
Dropout+Batch,0.8083999752998352,0.7946000099182129,551.5032987594604,0.4195821285247803
Dropout+Batch,0.7979999780654907,0.7835999727249146,346.3008089065552,0.4702033996582031
Dropout+Batch,0.803600013256073,0.7874000072479248,459.8723635673523,0.4527158737182617
Dropout+Batch,0.7997999787330627,0.7821999788284302,253.57676887512207,0.4811840057373047
